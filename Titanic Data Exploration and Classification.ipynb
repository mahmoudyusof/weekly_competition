{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data Exploration and Classification\n",
    "Hello, again. In this notebook, we'll go through some of the basic analysis and visualization techniques on the titanic dataset. We'll also try to classify the survivors using some basic machine learning models. The titanic dataset is very popular among beginners and often used for explaination purposes. Let's get right in to it.\n",
    "\n",
    "## Data Exploration\n",
    "\n",
    "### Loading and looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", index_col=\"PassengerId\")\n",
    "test_df = pd.read_csv(\"test.csv\", index_col=\"PassengerId\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pretty much know the types of data columns, but let me recall them\n",
    "\n",
    "- Numerical continous data (Data that consists of numbers taking any value like age or temprature)\n",
    "    - Age\n",
    "    - Fare\n",
    "- Numerical descrete data (Data that indicates a quantity but takes only descrete values)\n",
    "    - SibSp\n",
    "- Categorical data (Data that takes descrete values indicating categories like sex or race)\n",
    "    - Sex (Nominal)\n",
    "    - Pclass (Ordinal)\n",
    "    - Parch (Nominal)\n",
    "    - Cabin (Nominal)\n",
    "    - Embarked (Nominal)\n",
    "    \n",
    "Our label that we want to predict is the Survived column which takes values of 0 (died) or 1 (survived).  \n",
    "Let's explore the data a bit more by calling [DataFrame.info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Age, Cabin and Embarked columns have some null values ... let's try to fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## age is a continous numerical variable, I am going to use the median to fill the null values\n",
    "print(train_df[\"Age\"].isnull().sum())\n",
    "train_df[\"Age\"].fillna(train_df[\"Age\"].mean(), inplace=True)\n",
    "print(train_df[\"Age\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## now let's see the embarked column, it's a categorical column, let's see how many categories exist.\n",
    "freq = train_df[\"Embarked\"].fillna(\"None\").value_counts(normalize=True)\n",
    "plt.bar(freq.index, freq.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's use the most frequent value to replace unkown values\n",
    "train_df[\"Embarked\"].fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now let's look at the values of the cabin series\n",
    "train_df[\"Cabin\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More that half of the values are unique, remember that there are only 204 known values in this column.  \n",
    "Let's just drop it as it won't be so useful as is.  \n",
    "There might be some sort of preprocessing that can make it work, however let's just drop it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ticket column\n",
    "train_df[\"Ticket\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tickets are also highly unique, so they might just confuse the model, so we'll drop that to.  \n",
    "Now let's prepare our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, embarked_mapping=None):\n",
    "    # drop un-needed columns\n",
    "    df = df.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"])\n",
    "    \n",
    "    # emputing null values\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "    \n",
    "    # binary encoding\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "    \n",
    "    # Standardizing numerical variables\n",
    "    df[\"Fare\"] = (df[\"Fare\"].values - df[\"Fare\"].mean()) / df[\"Fare\"].std()\n",
    "    df[\"Age\"] = (df[\"Age\"].values - df[\"Age\"].mean()) / df[\"Age\"].std()\n",
    "    \n",
    "    if embarked_mapping is None:\n",
    "        # calculating means for mean encoding\n",
    "        # in pandas you can put a condition in the square brackets\n",
    "        # to select rows depending on that condition\n",
    "        embarked_mapping = {\n",
    "            \"S\": df[df[\"Embarked\"] == \"S\"][\"Survived\"].mean(),\n",
    "            \"C\": df[df[\"Embarked\"] == \"C\"][\"Survived\"].mean(),\n",
    "            \"Q\": df[df[\"Embarked\"] == \"Q\"][\"Survived\"].mean(),\n",
    "        }\n",
    "    \n",
    "    df[\"Embarked\"] = df[\"Embarked\"].map(embarked_mapping)\n",
    "    \n",
    "    ## the reason why we need the embarked_mappin dict is that in the test data we don't have the target\n",
    "    ## so we cannot calculate the means for mean encoding, you always use the training encoding again\n",
    "    return df, embarked_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.592148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0.339009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>0.339009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>0.339009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0.339009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "PassengerId                                                                   \n",
       "1                   0       3    0 -0.592148      1      0 -0.502163  0.339009\n",
       "2                   1       1    1  0.638430      1      0  0.786404  0.553571\n",
       "3                   1       3    1 -0.284503      0      0 -0.488580  0.339009\n",
       "4                   1       1    1  0.407697      1      0  0.420494  0.339009\n",
       "5                   0       3    0  0.407697      0      0 -0.486064  0.339009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_preprocessed, embarked_map = preprocess(train_df)\n",
    "train_df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Now let's classify the passengers, but before we do we need to explain two important concepts. \n",
    "Concepts of the day:\n",
    "- Cross validation (KFold)\n",
    "- Grid Search\n",
    "\n",
    "let's see each one of them alone\n",
    "\n",
    "### Cross validation\n",
    "Remeber back in the day when we used to split the data into train and test data? what if we split the data into $k$ parts, train the model on $k-1$ parts and validate against the last part, and repeat this for all splits of the data calculating our metric each time and averaging the results.. this is simply cross validation and it is very helpful to prevent overfitting or misleading evaluation metrics.  \n",
    "Let's use the function [sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)  \n",
    "see also:\n",
    "- [sklearn.model_selection.cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)\n",
    "- [sklearn.model_selection.cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7877095 , 0.78651685, 0.78651685, 0.76404494, 0.82022472])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "X = train_df_preprocessed.drop(columns=[\"Survived\"])\n",
    "y = train_df_preprocessed[\"Survived\"]\n",
    "\n",
    "cross_val_score(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8047138 , 0.82828283, 0.82154882])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "\n",
    "cross_val_score(model, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the svc model has a lot of parameters, how to choose between them? should we try all of them? this seems like a very booring process, what if we can automate it? well we can\n",
    "### Grid search\n",
    "Grid search is basically a very easy way to choose between parameters you can give to a model, we are not going to go into much details about the parameters you can give to the svc model, but you can always read the docs.\n",
    "\n",
    "[sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)  \n",
    "[sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ...................... C=1, gamma=1, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] .................... C=1, gamma=0.1, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ..................... C=1, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] .................. C=1, gamma=0.001, kernel=linear, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........................ C=10, gamma=1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=   0.1s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=   0.1s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ..................... C=10, gamma=1, kernel=linear, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ...................... C=10, gamma=0.1, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ................... C=10, gamma=0.1, kernel=linear, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] ................. C=10, gamma=0.001, kernel=linear, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] .............. C=1, degree=2, gamma=1, kernel=poly, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] .............. C=1, degree=2, gamma=1, kernel=poly, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=1, kernel=poly .............................\n",
      "[CV] .............. C=1, degree=2, gamma=1, kernel=poly, total=   0.1s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV] ............ C=1, degree=2, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV] ............ C=1, degree=2, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.1, kernel=poly ...........................\n",
      "[CV] ............ C=1, degree=2, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV] .......... C=1, degree=2, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV] .......... C=1, degree=2, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=2, gamma=0.001, kernel=poly .........................\n",
      "[CV] .......... C=1, degree=2, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] .............. C=1, degree=3, gamma=1, kernel=poly, total=   0.7s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] .............. C=1, degree=3, gamma=1, kernel=poly, total=   0.9s\n",
      "[CV] C=1, degree=3, gamma=1, kernel=poly .............................\n",
      "[CV] .............. C=1, degree=3, gamma=1, kernel=poly, total=   2.2s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV] ............ C=1, degree=3, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV] ............ C=1, degree=3, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.1, kernel=poly ...........................\n",
      "[CV] ............ C=1, degree=3, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV] .......... C=1, degree=3, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV] .......... C=1, degree=3, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=1, degree=3, gamma=0.001, kernel=poly .........................\n",
      "[CV] .......... C=1, degree=3, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV] ............. C=10, degree=2, gamma=1, kernel=poly, total=   0.5s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV] ............. C=10, degree=2, gamma=1, kernel=poly, total=   0.6s\n",
      "[CV] C=10, degree=2, gamma=1, kernel=poly ............................\n",
      "[CV] ............. C=10, degree=2, gamma=1, kernel=poly, total=   1.1s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV] ........... C=10, degree=2, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV] ........... C=10, degree=2, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.1, kernel=poly ..........................\n",
      "[CV] ........... C=10, degree=2, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV] ......... C=10, degree=2, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV] ......... C=10, degree=2, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=2, gamma=0.001, kernel=poly ........................\n",
      "[CV] ......... C=10, degree=2, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV] ............. C=10, degree=3, gamma=1, kernel=poly, total=   7.2s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV] ............. C=10, degree=3, gamma=1, kernel=poly, total=  10.5s\n",
      "[CV] C=10, degree=3, gamma=1, kernel=poly ............................\n",
      "[CV] ............. C=10, degree=3, gamma=1, kernel=poly, total=  12.2s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV] ........... C=10, degree=3, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV] ........... C=10, degree=3, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.1, kernel=poly ..........................\n",
      "[CV] ........... C=10, degree=3, gamma=0.1, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV] ......... C=10, degree=3, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV] ......... C=10, degree=3, gamma=0.001, kernel=poly, total=   0.0s\n",
      "[CV] C=10, degree=3, gamma=0.001, kernel=poly ........................\n",
      "[CV] ......... C=10, degree=3, gamma=0.001, kernel=poly, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   37.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 10], 'gamma': [1, 0.1, 0.001],\n",
       "                          'kernel': ['rbf', 'linear']},\n",
       "                         {'C': [1, 10], 'degree': [2, 3],\n",
       "                          'gamma': [1, 0.1, 0.001], 'kernel': ['poly']}],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## first we define the parameter grid,\n",
    "## the grid search algorithm is simply going to create a model, fit it with each and every possible\n",
    "## set of parameters, and then evaluate models using cross validation and keep the best model and\n",
    "## best paramters\n",
    "param_grid = [\n",
    "    {\n",
    "        \"gamma\": [1, 0.1,0.001],\n",
    "        \"C\": [1,10],\n",
    "        \"kernel\": [\"rbf\", \"linear\"]\n",
    "    },\n",
    "    {\n",
    "        \"gamma\": [1,0.1,0.001],\n",
    "        \"C\": [1,10],\n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"degree\": [2, 3]\n",
    "    }\n",
    "]\n",
    "\n",
    "# we pass the model, the grid and the splits of the cross validation\n",
    "# the verbose parameter is just to output a lot of data from the process\n",
    "# you'll see what I mean\n",
    "grid_search = GridSearchCV(SVC(), param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226711560044894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the best score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    int64  \n",
      " 2   Age       418 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Fare      417 non-null    float64\n",
      " 6   Embarked  418 non-null    float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 26.1 KB\n"
     ]
    }
   ],
   "source": [
    "## now let's get the best model and do some predictions\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "test_df_preprocessed, embarked_map = preprocess(test_df, embarked_mapping=embarked_map)\n",
    "\n",
    "test_df_preprocessed.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seems like the fare column has a null value, take good care since you might find nulls in columns\n",
    "## in the test data that didn't have nulls in the training, it happened with me but I am covering it now XD\n",
    "\n",
    "test_df_preprocessed[\"Fare\"].fillna(test_df_preprocessed[\"Fare\"].mean(), inplace=True)\n",
    "\n",
    "preds = model.predict(test_df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 1\n",
       "894                 0\n",
       "895                 0\n",
       "896                 0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now let's create a submission\n",
    "test_df[\"Survived\"] = preds\n",
    "test_df = test_df[[\"Survived\"]]\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search\n",
    "Now you try, search for random search on google and read the docs on it and see what you can do with it and when to use it. good luck\n",
    "\n",
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
